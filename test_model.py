# test_model.py
# æµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹æ€§èƒ½
import os
import json
import random
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
from collections import Counter

def load_test_data(test_file_path, num_samples=100):
    """
    ä»æµ‹è¯•æ–‡ä»¶ä¸­éšæœºåŠ è½½æŒ‡å®šæ•°é‡çš„æ ·æœ¬
    """
    with open(test_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # éšæœºé€‰æ‹©æ ·æœ¬
    if len(data) > num_samples:
        selected_data = random.sample(data, num_samples)
    else:
        selected_data = data
    
    texts = [item['content'] for item in selected_data]
    labels = [item['label'] for item in selected_data]
    
    print(f"âœ… åŠ è½½æµ‹è¯•æ•°æ®: {len(selected_data)} æ¡æ ·æœ¬")
    print("æµ‹è¯•æ•°æ®æ ‡ç­¾åˆ†å¸ƒ:", Counter(labels))
    
    return texts, labels

def load_model_and_tokenizer(model_path):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å’Œåˆ†è¯å™¨
    """
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    model = AutoModelForSequenceClassification.from_pretrained(model_path)
    
    # åŠ è½½æ ‡ç­¾æ˜ å°„
    with open(os.path.join(model_path, 'label_mapping.json'), 'r', encoding='utf-8') as f:
        label_mapping = json.load(f)
    
    return model, tokenizer, label_mapping

def predict_texts(model, tokenizer, texts, label_mapping, max_length=256):
    """
    å¯¹æ–‡æœ¬è¿›è¡Œæ‰¹é‡é¢„æµ‹
    """
    model.eval()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model.to(device)
    
    predictions = []
    id2label = label_mapping['id2label']
    
    # åŠ è½½logit biasï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    logit_bias = None
    try:
        # æ ¹æ®è®­ç»ƒæ—¶çš„è®¾ç½®è®¡ç®—logit bias
        label2id = label_mapping['label2id']
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥ä»è®­ç»ƒå‚æ•°ä¸­è·å–
        logit_bias = torch.zeros(len(label2id))
    except:
        pass
    
    with torch.no_grad():
        for text in texts:
            # æ–‡æœ¬é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
            import re
            _url = re.compile(r'https?://\S+|www\.\S+')
            _at = re.compile(r'@\S+')
            _topic = re.compile(r'#([^#]+)#')
            _space = re.compile(r'\s+')
            
            clean_text = _url.sub(' ', str(text))
            clean_text = _at.sub(' ', clean_text)
            clean_text = _topic.sub(r'\1', clean_text)
            clean_text = clean_text.replace('è½¬å‘å¾®åš', ' ').replace('æ¥è‡ª', ' ')
            clean_text = _space.sub(' ', clean_text).strip()
            
            # åˆ†è¯å’Œç¼–ç 
            inputs = tokenizer(clean_text, 
                             return_tensors='pt', 
                             truncation=True, 
                             max_length=max_length,
                             padding=True)
            inputs = {k: v.to(device) for k, v in inputs.items()}
            
            # é¢„æµ‹
            outputs = model(**inputs)
            logits = outputs.logits
            
            # åº”ç”¨logit biasï¼ˆå¦‚æœæœ‰ï¼‰
            if logit_bias is not None:
                logits = logits + logit_bias.to(device)
            
            pred_id = torch.argmax(logits, dim=-1).item()
            pred_label = id2label[str(pred_id)]
            predictions.append(pred_label)
    
    return predictions

def evaluate_model(true_labels, pred_labels, label_mapping):
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½
    """
    # è®¡ç®—åŸºæœ¬æŒ‡æ ‡
    accuracy = accuracy_score(true_labels, pred_labels)
    f1_macro = f1_score(true_labels, pred_labels, average='macro')
    f1_weighted = f1_score(true_labels, pred_labels, average='weighted')
    
    print(f"\nğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°ç»“æœ:")
    print(f"å‡†ç¡®ç‡ (Accuracy): {accuracy:.4f}")
    print(f"å®å¹³å‡F1åˆ†æ•°: {f1_macro:.4f}")
    print(f"åŠ æƒå¹³å‡F1åˆ†æ•°: {f1_weighted:.4f}")
    
    # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
    unique_labels = sorted(list(set(true_labels + pred_labels)))
    print(f"\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(true_labels, pred_labels, 
                              target_names=unique_labels, 
                              digits=4))
    
    # æ··æ·†çŸ©é˜µ
    print(f"\nğŸ”¢ æ··æ·†çŸ©é˜µ:")
    cm = confusion_matrix(true_labels, pred_labels, labels=unique_labels)
    print("æ ‡ç­¾é¡ºåº:", unique_labels)
    print(cm)
    
    # é”™è¯¯åˆ†æ
    print(f"\nâŒ é”™è¯¯åˆ†æ:")
    errors = []
    for i, (true, pred) in enumerate(zip(true_labels, pred_labels)):
        if true != pred:
            errors.append((i, true, pred))
    
    print(f"æ€»é”™è¯¯æ•°: {len(errors)} / {len(true_labels)}")
    if len(errors) > 0:
        error_types = Counter([(true, pred) for _, true, pred in errors])
        print("ä¸»è¦é”™è¯¯ç±»å‹:")
        for (true, pred), count in error_types.most_common(5):
            print(f"  {true} -> {pred}: {count} æ¬¡")
    
    return accuracy, f1_macro, f1_weighted

def main():
    # è®¾ç½®éšæœºç§å­
    random.seed(42)
    np.random.seed(42)
    torch.manual_seed(42)
    
    # æ–‡ä»¶è·¯å¾„
    test_file = "./data/test/usual_test_labeled.txt"
    model_path = "./runs/distilbert_balanced20k_retrain"
    
    print("ğŸš€ å¼€å§‹æ¨¡å‹æµ‹è¯•...")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(test_file):
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}")
        return
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        return
    
    # åŠ è½½æµ‹è¯•æ•°æ®
    texts, true_labels = load_test_data(test_file, num_samples=1000)
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ“¦ åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")
    model, tokenizer, label_mapping = load_model_and_tokenizer(model_path)
    print(f"æ¨¡å‹æ ‡ç­¾: {list(label_mapping['label2id'].keys())}")
    
    # è¿›è¡Œé¢„æµ‹
    print("\nğŸ”® å¼€å§‹é¢„æµ‹...")
    pred_labels = predict_texts(model, tokenizer, texts, label_mapping)
    
    # è¯„ä¼°æ€§èƒ½
    accuracy, f1_macro, f1_weighted = evaluate_model(true_labels, pred_labels, label_mapping)
    
    # æ˜¾ç¤ºä¸€äº›é¢„æµ‹ç¤ºä¾‹
    print(f"\nğŸ” é¢„æµ‹ç¤ºä¾‹ (å‰10æ¡):")
    for i in range(min(10, len(texts))):
        status = "âœ…" if true_labels[i] == pred_labels[i] else "âŒ"
        print(f"{status} æ–‡æœ¬: {texts[i][:50]}...")
        print(f"   çœŸå®æ ‡ç­¾: {true_labels[i]} | é¢„æµ‹æ ‡ç­¾: {pred_labels[i]}")
        print()
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")

if __name__ == "__main__":
    main()